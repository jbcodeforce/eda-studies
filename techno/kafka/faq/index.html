<!doctype html><html lang=en class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><link href=https://jeromeboyer.net/eda-studies/techno/kafka/faq/ rel=canonical><link href=../ rel=prev><link href=../producer/ rel=next><link rel=icon href=../../../images/logo-blue.drawio.png><meta name=generator content="mkdocs-1.6.1, mkdocs-material-9.6.14"><title>Kafka FAQ - Event-Driven Solutions in Hybrid Cloud - Jerome Boyer</title><link rel=stylesheet href=../../../assets/stylesheets/main.342714a4.min.css><link rel=stylesheet href=../../../assets/stylesheets/palette.06af60db.min.css><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback"><style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style><link rel=stylesheet href=../../../extra.css><script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script></head> <body dir=ltr data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=indigo> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href=#frequently-asked-questions class=md-skip> Skip to content </a> </div> <div data-md-component=announce> </div> <header class="md-header md-header--shadow md-header--lifted" data-md-component=header> <nav class="md-header__inner md-grid" aria-label=Header> <a href=../../.. title="Event-Driven Solutions in Hybrid Cloud - Jerome Boyer" class="md-header__button md-logo" aria-label="Event-Driven Solutions in Hybrid Cloud - Jerome Boyer" data-md-component=logo> <img src=../../../images/logo.drawio.png alt=logo> </a> <label class="md-header__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg> </label> <div class=md-header__title data-md-component=header-title> <div class=md-header__ellipsis> <div class=md-header__topic> <span class=md-ellipsis> Event-Driven Solutions in Hybrid Cloud - Jerome Boyer </span> </div> <div class=md-header__topic data-md-component=header-topic> <span class=md-ellipsis> Kafka FAQ </span> </div> </div> </div> <label class="md-header__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=Search placeholder=Search autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query required> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg> </label> <nav class=md-search__options aria-label=Search> <button type=reset class="md-search__icon md-icon" title=Clear aria-label=Clear tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg> </button> </nav> </form> <div class=md-search__output> <div class=md-search__scrollwrap tabindex=0 data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> Initializing search </div> <ol class=md-search-result__list role=presentation></ol> </div> </div> </div> </div> </div> <div class=md-header__source> <a href=https://github.com/jbcodeforce/eda-studies.git title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg> </div> <div class=md-source__repository> GitHub </div> </a> </div> </nav> <nav class=md-tabs aria-label=Tabs data-md-component=tabs> <div class=md-grid> <ul class=md-tabs__list> <li class=md-tabs__item> <a href=../../.. class=md-tabs__link> Home </a> </li> <li class=md-tabs__item> <a href=../../../concepts/eda/ class=md-tabs__link> EDA concepts </a> </li> <li class=md-tabs__item> <a href=../../../methodology/event-storming/ class=md-tabs__link> Methodology </a> </li> <li class=md-tabs__item> <a href=../../../patterns/ class=md-tabs__link> Design patterns </a> </li> <li class=md-tabs__item> <a href=../../../methodology/getting-started/ class=md-tabs__link> Demonstrations </a> </li> <li class="md-tabs__item md-tabs__item--active"> <a href=../ class=md-tabs__link> Technologies </a> </li> </ul> </div> </nav> </header> <div class=md-container data-md-component=container> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=sidebar data-md-type=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary md-nav--lifted" aria-label=Navigation data-md-level=0> <label class=md-nav__title for=__drawer> <a href=../../.. title="Event-Driven Solutions in Hybrid Cloud - Jerome Boyer" class="md-nav__button md-logo" aria-label="Event-Driven Solutions in Hybrid Cloud - Jerome Boyer" data-md-component=logo> <img src=../../../images/logo.drawio.png alt=logo> </a> Event-Driven Solutions in Hybrid Cloud - Jerome Boyer </label> <div class=md-nav__source> <a href=https://github.com/jbcodeforce/eda-studies.git title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg> </div> <div class=md-source__repository> GitHub </div> </a> </div> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../.. class=md-nav__link> <span class=md-ellipsis> Home </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_2> <label class=md-nav__link for=__nav_2 id=__nav_2_label tabindex=0> <span class=md-ellipsis> EDA concepts </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_2_label aria-expanded=false> <label class=md-nav__title for=__nav_2> <span class="md-nav__icon md-icon"></span> EDA concepts </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../concepts/eda/ class=md-nav__link> <span class=md-ellipsis> Reference architecture </span> </a> </li> <li class=md-nav__item> <a href=../../../concepts/soa-eda/ class=md-nav__link> <span class=md-ellipsis> From SOA to EDA </span> </a> </li> <li class=md-nav__item> <a href=../../../concepts/backbone/ class=md-nav__link> <span class=md-ellipsis> Messaging backbone </span> </a> </li> <li class=md-nav__item> <a href=../../../concepts/legacy-itg/ class=md-nav__link> <span class=md-ellipsis> Legacy integration </span> </a> </li> <li class=md-nav__item> <a href=../../../concepts/data-pipeline/ class=md-nav__link> <span class=md-ellipsis> Data pipeline </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_3> <label class=md-nav__link for=__nav_3 id=__nav_3_label tabindex=0> <span class=md-ellipsis> Methodology </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_3_label aria-expanded=false> <label class=md-nav__title for=__nav_3> <span class="md-nav__icon md-icon"></span> Methodology </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../methodology/event-storming/ class=md-nav__link> <span class=md-ellipsis> Event Storming </span> </a> </li> <li class=md-nav__item> <a href=../../../methodology/ddd/ class=md-nav__link> <span class=md-ellipsis> Domain driven design </span> </a> </li> <li class=md-nav__item> <a href=../../../methodology/ddd/eda_assessment/ class=md-nav__link> <span class=md-ellipsis> EDA Assessment </span> </a> </li> <li class=md-nav__item> <a href=../../../methodology/event-storming/vaccine-dt-es-ddd/ class=md-nav__link> <span class=md-ellipsis> Vaccine Examples </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_4> <label class=md-nav__link for=__nav_4 id=__nav_4_label tabindex=0> <span class=md-ellipsis> Design patterns </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_4_label aria-expanded=false> <label class=md-nav__title for=__nav_4> <span class="md-nav__icon md-icon"></span> Design patterns </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../patterns/ class=md-nav__link> <span class=md-ellipsis> Common patterns </span> </a> </li> <li class=md-nav__item> <a href=../../../patterns/events-versus-messages/ class=md-nav__link> <span class=md-ellipsis> Messaging vs events </span> </a> </li> <li class=md-nav__item> <a href=../../../patterns/model/ class=md-nav__link> <span class=md-ellipsis> Devising the data models </span> </a> </li> <li class=md-nav__item> <a href=../../../patterns/api-mgt/ class=md-nav__link> <span class=md-ellipsis> API management </span> </a> </li> <li class=md-nav__item> <a href=../../../patterns/saga/ class=md-nav__link> <span class=md-ellipsis> Saga </span> </a> </li> <li class=md-nav__item> <a href=../../../patterns/event-sourcing/ class=md-nav__link> <span class=md-ellipsis> Event Sourcing </span> </a> </li> <li class=md-nav__item> <a href=../../../patterns/cqrs/ class=md-nav__link> <span class=md-ellipsis> CQRS </span> </a> </li> <li class=md-nav__item> <a href=../../../patterns/reactive/ class=md-nav__link> <span class=md-ellipsis> Reactive </span> </a> </li> <li class=md-nav__item> <a href=../../../patterns/flow-architectures/ class=md-nav__link> <span class=md-ellipsis> Flow architecture </span> </a> </li> <li class=md-nav__item> <a href=../../../patterns/dlq/ class=md-nav__link> <span class=md-ellipsis> Dead letter queue </span> </a> </li> <li class=md-nav__item> <a href=../../../patterns/data-lineage/ class=md-nav__link> <span class=md-ellipsis> Data lineage </span> </a> </li> <li class=md-nav__item> <a href=../../../patterns/governance/ class=md-nav__link> <span class=md-ellipsis> Governance </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_5> <label class=md-nav__link for=__nav_5 id=__nav_5_label tabindex=0> <span class=md-ellipsis> Demonstrations </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_5_label aria-expanded=false> <label class=md-nav__title for=__nav_5> <span class="md-nav__icon md-icon"></span> Demonstrations </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../methodology/getting-started/ class=md-nav__link> <span class=md-ellipsis> Getting Started </span> </a> </li> <li class=md-nav__item> <a href=../playground/ class=md-nav__link> <span class=md-ellipsis> Sandbox notes </span> </a> </li> <li class=md-nav__item> <a href=../../../solutions/gitops_IaC/ class=md-nav__link> <span class=md-ellipsis> GitOps - IaC </span> </a> </li> <li class=md-nav__item> <a href=https://jbcodeforce.github.io/eda-rt-inventory/ class=md-nav__link> <span class=md-ellipsis> Real-time Inventory </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_6 checked> <label class=md-nav__link for=__nav_6 id=__nav_6_label tabindex> <span class=md-ellipsis> Technologies </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_6_label aria-expanded=true> <label class=md-nav__title for=__nav_6> <span class="md-nav__icon md-icon"></span> Technologies </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../ class=md-nav__link> <span class=md-ellipsis> Kafka </span> </a> </li> <li class="md-nav__item md-nav__item--active"> <input class="md-nav__toggle md-toggle" type=checkbox id=__toc> <label class="md-nav__link md-nav__link--active" for=__toc> <span class=md-ellipsis> Kafka FAQ </span> <span class="md-nav__icon md-icon"></span> </label> <a href=./ class="md-nav__link md-nav__link--active"> <span class=md-ellipsis> Kafka FAQ </span> </a> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#basic-questions class=md-nav__link> <span class=md-ellipsis> Basic questions </span> </a> </li> <li class=md-nav__item> <a href=#security-questions class=md-nav__link> <span class=md-ellipsis> Security questions </span> </a> </li> <li class=md-nav__item> <a href=#more-advanced-concepts class=md-nav__link> <span class=md-ellipsis> More advanced concepts </span> </a> </li> <li class=md-nav__item> <a href=#kafka-connect class=md-nav__link> <span class=md-ellipsis> Kafka Connect </span> </a> </li> <li class=md-nav__item> <a href=#derived-products-related-questions class=md-nav__link> <span class=md-ellipsis> Derived products related questions </span> </a> </li> <li class=md-nav__item> <a href=#other-faqs class=md-nav__link> <span class=md-ellipsis> Other FAQs </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../producer/ class=md-nav__link> <span class=md-ellipsis> Kafka Producer </span> </a> </li> <li class=md-nav__item> <a href=../consumer/ class=md-nav__link> <span class=md-ellipsis> Kafka Consumer </span> </a> </li> <li class=md-nav__item> <a href=../security/ class=md-nav__link> <span class=md-ellipsis> Kafka Security </span> </a> </li> <li class=md-nav__item> <a href=../../avro-schemas/ class=md-nav__link> <span class=md-ellipsis> Schema Mgt </span> </a> </li> <li class=md-nav__item> <a href=../../kstreams/ class=md-nav__link> <span class=md-ellipsis> Kafka Streams </span> </a> </li> <li class=md-nav__item> <a href=../../kafka-connect/ class=md-nav__link> <span class=md-ellipsis> Kafka Connect </span> </a> </li> <li class=md-nav__item> <a href=../../confluent/ class=md-nav__link> <span class=md-ellipsis> Confluent </span> </a> </li> <li class=md-nav__item> <a href=https://jbcodeforce.github.io/redpanda-studies/ class=md-nav__link> <span class=md-ellipsis> RedPanda </span> </a> </li> <li class=md-nav__item> <a href=../../mirrormaker/ class=md-nav__link> <span class=md-ellipsis> Mirror Maker 2 </span> </a> </li> <li class=md-nav__item> <a href=https://jbcodeforce.github.io/flink-studies class=md-nav__link> <span class=md-ellipsis> Flink </span> </a> </li> <li class=md-nav__item> <a href=https://jbcodeforce.github.io/aws-messaging-study/activemq/ class=md-nav__link> <span class=md-ellipsis> Active MQ </span> </a> </li> <li class=md-nav__item> <a href=https://jbcodeforce.github.io/aws-messaging-study/rabbitmq/ class=md-nav__link> <span class=md-ellipsis> Rabbit MQ </span> </a> </li> <li class=md-nav__item> <a href=../../../solutions/autonomous-car/es-duplicate-evt/ class=md-nav__link> <span class=md-ellipsis> AWS duplicate with EB </span> </a> </li> <li class=md-nav__item> <a href=https://jbcodeforce.github.io/yarfba/kinesis class=md-nav__link> <span class=md-ellipsis> AWS Kinesis </span> </a> </li> <li class=md-nav__item> <a href=https://jbcodeforce.github.io/yarfba/serverless/msk class=md-nav__link> <span class=md-ellipsis> AWS MSK </span> </a> </li> <li class=md-nav__item> <a href=https://jbcodeforce.github.io/aws-messaging-study class=md-nav__link> <span class=md-ellipsis> AWS messaging </span> </a> </li> <li class=md-nav__item> <a href=https://jbcodeforce.github.io/aws-messaging-study/sqs/ class=md-nav__link> <span class=md-ellipsis> AWS SQS </span> </a> </li> <li class=md-nav__item> <a href=../../../ibm-assets/ class=md-nav__link> <span class=md-ellipsis> IBM Assets </span> </a> </li> <li class=md-nav__item> <a href=../../ibm-mq/ class=md-nav__link> <span class=md-ellipsis> IBM MQ </span> </a> </li> </ul> </nav> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=sidebar data-md-type=toc> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#basic-questions class=md-nav__link> <span class=md-ellipsis> Basic questions </span> </a> </li> <li class=md-nav__item> <a href=#security-questions class=md-nav__link> <span class=md-ellipsis> Security questions </span> </a> </li> <li class=md-nav__item> <a href=#more-advanced-concepts class=md-nav__link> <span class=md-ellipsis> More advanced concepts </span> </a> </li> <li class=md-nav__item> <a href=#kafka-connect class=md-nav__link> <span class=md-ellipsis> Kafka Connect </span> </a> </li> <li class=md-nav__item> <a href=#derived-products-related-questions class=md-nav__link> <span class=md-ellipsis> Derived products related questions </span> </a> </li> <li class=md-nav__item> <a href=#other-faqs class=md-nav__link> <span class=md-ellipsis> Other FAQs </span> </a> </li> </ul> </nav> </div> </div> </div> <div class=md-content data-md-component=content> <article class="md-content__inner md-typeset"> <h1 id=frequently-asked-questions>Frequently asked questions<a class=headerlink href=#frequently-asked-questions title="Permanent link">&para;</a></h1> <h2 id=basic-questions>Basic questions<a class=headerlink href=#basic-questions title="Permanent link">&para;</a></h2> <details class="- question"> <summary>What is Kafka?</summary> <ul> <li>Pub/sub middleware to share data between applications</li> <li>Open source, started in 2011 by Linkedin</li> <li>Based on append log to persist immutable records ordered by arrival.</li> <li>Support data partitioning, distributed brokers, horizontal scaling, low-latency and high throughput.</li> <li>Producer has no knowledge of consumers</li> <li>Records stay even after being consumed</li> <li>Durability with replication to avoid loosing data for high availability</li> </ul> </details> <details class="- question"> <summary>What are the Kafka major components?</summary> <ul> <li>Topic, consumer, producer, brokers, cluster <a href=../ >see this note for deep dive</a></li> <li>Rich API to control the producer semantic, and consumer</li> <li>Consumer groups. <a href=../consumer/#consumer-group>See this note for detail</a></li> <li>Kafka streams API to support data streaming with stateful operations and stream processing topology</li> <li>Kafka connect for source and sink connection to external systems</li> <li>Topic replication with Mirror Maker 2</li> </ul> <p><img alt src=../images/kafka-components.png></p> </details> <details class="- question"> <summary>What are major use cases?</summary> <ul> <li>Modern data pipeline with buffering to data lake</li> <li>Data hub, to continuously expose business entities to event-driven applications and microservices</li> <li>Real time analytics with aggregate computation, and complex event processing</li> <li>The communication layer for Event-driven, reactive microservice.</li> </ul> </details> <details class="- question"> <summary>Why does Kafka use zookeeper?</summary> <p>Kafka as a distributed system using cluster, it needs to keep cluster states, sharing configuration like topic, assess which node is still alive within the cluster, support registering new node added to the cluster, being able to support dynamic restart. Zookeeper is an orchestrator for distributed system, it maintains Kafka cluster integrity, select broker leader... </p> <p>Zookeeper is also used to manage offset commit, and to the leader selection process.</p> <p>Version 2.8 introduces another algorithm to define partition leadership and cluster health via one broker becoming the cluster controller. See <a href=https://www.confluent.io/blog/kafka-2-8-0-features-and-improvements-with-early-access-to-kip-500/ >this note on KIP 500</a></p> </details> <details class="- question"> <summary>What is a replica?</summary> <p>Nodes responsible to participate into the data replication process for a given partition. It is a critical feature to ensure durability, be able to continue to consume records, or to ensure a certain level of data loss safety is guaranteed when producing records.</p> </details> <details class="- question"> <summary>What are a leader and follower in Kafka?</summary> <p>Topic has 1 to many partition, which are append logs. Every partition in Kafka has a server that plays the role of <strong>leader</strong> . Leader receives read and write operation, and ensure acknowledge management. When replication is set in a topic, follower brokers will pull data from the leader to ensure replication, up to the specified replication factor. If the leader fails, one of the followers needs to take over as the leader’s role. The leader election process involves zookeeper and assesses which follower was the most in-synch with the leader. </p> <p>To get the list of In-synch Replication for a given topic the following tool can be used:</p> <div class="language-shell highlight"><pre><span></span><code><span id=__span-0-1><a id=__codelineno-0-1 name=__codelineno-0-1 href=#__codelineno-0-1></a>kafka-topics.sh<span class=w> </span>--bootstrap-server<span class=w> </span>:9092<span class=w> </span>--describe<span class=w> </span>--topic<span class=w> </span>&lt;topicname&gt;
</span></code></pre></div> </details> <details class="- question"> <summary>What is Offset?</summary> <p>A unique identifier of records inside a partition. It is automatically created by the broker, and producer can get it from the broker response. Consumer uses it to commit its read. It means, in case of consumer restarts, it will read from the last committed offset.</p> </details> <details class="- question"> <summary>What is a consumer group?</summary> <p>It groups consumers of one to many topics. Each partition is consumed by exactly one consumer within each subscribing <a href=../consumer/#consumer-group>consumer group</a>.</p> <p>Consumer group is specified via the <code>group.id</code> consumer's property, and when consumers subscribe to topic(s).</p> <p>There is a protocol to manage consumers within a group so that partition can be reallocated when a consumer lefts the group. The <em>group leader</em> is responsible to do the partition assignment.</p> <p>When using the <a href=https://kafka.apache.org/documentation/#consumerconfigs_group.instance.id>group.instance.id</a> properties, consumer is treated as a static member, which means there will be no partition re-balance when consumer lefts a group for a short time period. When not set, the group coordinator (a broker) will allocate <code>ids</code> to group members, and reallocation will occur. For Kafka Streams application, it is recommended to use static membership.</p> <p>Brokers keep offsets until a <a href=https://kafka.apache.org/documentation/#brokerconfigs_offsets.retention.minutes>retention period</a> within which consumer group can lose all its consumers. After that period, offsets are discarded. The consumer group can be deleted manually, or automatically when the last committed offset for that group expires.</p> <p>When the group coordinator receives an OffsetCommitRequest, it appends the request to a special compacted Kafka topic named __consumer_offsets. Ack from the broker is done once all replicas on this hidden topics are successful.</p> <p>The tool <code>kafka-consumer-group.sh</code> helps getting details of consumer group:</p> <div class="language-shell highlight"><pre><span></span><code><span id=__span-1-1><a id=__codelineno-1-1 name=__codelineno-1-1 href=#__codelineno-1-1></a><span class=c1># Inside a Kafka broker container</span>
</span><span id=__span-1-2><a id=__codelineno-1-2 name=__codelineno-1-2 href=#__codelineno-1-2></a>bin/kafka-consumer-groups.sh<span class=w> </span>--bootstrap-server<span class=w> </span>kafka:9092<span class=w> </span>--describe<span class=w> </span>--group<span class=w> </span>order-group<span class=w> </span>--members<span class=w> </span>--verbose
</span></code></pre></div> </details> <details class="- question"> <summary>How to support multi-tenancy?</summary> <p>Multi-tenant means multiple different groups of application can produce and consume messages isolated from each other. So by constructs, topics and brokers are multi-tenant. Now the control will be at the access control level policy, the use of service account, and naming convention on the topic name. Consumer and producer authenticate themselves using dedicated service account users, with SCRAM user or Mutual TLS user. Each topic can have security policy to control read, write, and creation operations.</p> </details> <details class="- question"> <summary>How client access Kafka cluster metadata?</summary> <p>Provide a list of Kafka brokers, minimum two, so the client API will get the metadata once connected to one of the broker.</p> </details> <details class="- question"> <summary>How to get at most once delivery?</summary> <p>Set producer acknowledge level (acks) property to 0 or 1.</p> </details> <details class="- question"> <summary>How to support exactly once delivery?</summary> <p>The goal is to address that, if a producer sends a message twice the system will keep only one message to the consumer, and once the consumer commits the read offset, it will not receive the message again even if it restarts.</p> <p>See the section in the producer implementation considerations <a href=../producer/#how-to-support-exactly-once-delivery>note</a>.</p> <p>The consumer needs to always read from its last committed offset.</p> <p>Also it is important to note that the Kafka Stream API supports exactly once semantics with the config: <code>processing.guarantee=exactly_once</code>. Each task within a read-process-write flow may fail so this setting is important to be sure the right answer is delivered, even in case of task failure, and the process is executed exactly once.</p> <p>Exactly-once delivery for other destination systems generally requires cooperation with such systems which may be possible by using the offset processing.</p> </details> <details class="- question"> <summary>Retention time for topic what does it mean?</summary> <p>The message sent to a cluster is kept for a max period of time or until a max size is reached. Those topic properties are: <code>retention.ms</code> and <code>retention.bytes</code>. Messages stay in the log even if they are consumed. The oldest messages are marked for deletion or compaction depending of the cleanup policy (delete or compact) set to <code>cleanup.policy</code> topic's parameter. See the Kafka documentation on <a href=https://kafka.apache.org/documentation/#topicconfigs>topic configuration parameters</a>.</p> <p>Here is a command to create a topic with specific retention properties:</p> <div class="language-shell highlight"><pre><span></span><code><span id=__span-2-1><a id=__codelineno-2-1 name=__codelineno-2-1 href=#__codelineno-2-1></a>bin/kafka-configs<span class=w> </span>--zookeeper<span class=w> </span>XX.XX.XX.XX:2181<span class=w> </span>--entity-type<span class=w> </span>topics<span class=w> </span>--entity-name<span class=w> </span>orders<span class=w> </span>--alter<span class=w> </span>--add-config<span class=w>  </span>retention.ms<span class=o>=</span><span class=m>55000</span><span class=w> </span>--add-config<span class=w>  </span>retention.byte<span class=o>=</span><span class=m>100000</span>
</span></code></pre></div> <p>But there is also the <code>offsets.retention.minutes</code> property, set at the cluster level to control when the offset information will be deleted. It is defaulted to 1 day, but the max possible value is 7 days. This is to avoid keeping too much information in the broker memory and avoid to miss data when consumers do not run continuously. So consumers need to commit their offset. If the consumer settings define: <code>auto.offset.reset=earliest</code>, the consumer will reprocess all the events each time it restarts, (or skips to the latest if set to <code>latest</code>). When using <code>latest</code>, if the consumers are offline for more than the offsets retention time window, they will lose events.</p> </details> <details class="- question"> <summary>What are the topic characteristics I need to define during requirements?</summary> <p>This is a requirement gathering related question to understand what need to be done for topic configuration but also consumer and producer configurations, as well as retention strategy.</p> <ul> <li>Number of brokers in the cluster.</li> <li>Retention time and size</li> <li>Need for HA, set replicas to number of broker or at least the value of 3, with in-synch replica to 2</li> <li>Type of data to transport to assess message size</li> <li>Plan to use schema management to control change to the payload definition</li> <li>Volume per day with peak and average</li> <li>Need to do geo replication to other Kafka cluster</li> <li>Network filesystem used on the target Kubernetes cluster and current storage class</li> </ul> </details> <details class="- question"> <summary>What are the impacts of having not enough resource for Kafka?</summary> <p>When resources start to be at stress, then Kafka communication to ZooKeeper and/or other Kafka brokers can suffer resulting in out-of-sync partitions and container restarts perpetuating the issue. Resource constraints is one of the first things to consider when diagnosing kafka broker issues.</p> </details> <h2 id=security-questions>Security questions<a class=headerlink href=#security-questions title="Permanent link">&para;</a></h2> <p>For deeper dive on security administration <a href=https://docs.confluent.io/platform/current/security/general-overview.html>see Confluent article</a> and <a href=http://kafka.apache.org/documentation/#security>Apache Kafka product documentation</a>.</p> <details class="- question"> <summary>What Security support in Kafka?</summary> <ul> <li>Encrypt data in transit between producer and Kafka brokers</li> <li>Client authentication</li> <li>Client authorization</li> </ul> </details> <details class="- question"> <summary>Explain security protocol</summary> <p><a href=http://kafka.apache.org/documentation/#adminclientconfigs_security.protocol>security.protocol</a> defines the protocol used to communicate with brokers. Verify how the listeners are configured in the Kafka cluster. The valid values are:</p> <div class="language-text highlight"><pre><span></span><code><span id=__span-3-1><a id=__codelineno-3-1 name=__codelineno-3-1 href=#__codelineno-3-1></a>PLAINTEXT (using PLAINTEXT transport layer &amp; no authentication - default value).
</span><span id=__span-3-2><a id=__codelineno-3-2 name=__codelineno-3-2 href=#__codelineno-3-2></a>SSL (using SSL transport layer &amp; certificate-based authentication)
</span><span id=__span-3-3><a id=__codelineno-3-3 name=__codelineno-3-3 href=#__codelineno-3-3></a>SASL_PLAINTEXT (using PLAINTEXT transport layer &amp; SASL-based authentication)
</span><span id=__span-3-4><a id=__codelineno-3-4 name=__codelineno-3-4 href=#__codelineno-3-4></a>SASL_SSL (using SSL transport layer &amp; SASL-based authentication)
</span></code></pre></div> <p>In Strimzi the following yaml defines the different listeners type and port: <code>tls</code> boolean is for the traffic encryption, while <code>authentication.type</code> defines the matching security protocol.</p> <div class="language-yaml highlight"><pre><span></span><code><span id=__span-4-1><a id=__codelineno-4-1 name=__codelineno-4-1 href=#__codelineno-4-1></a><span class=nt>listeners</span><span class=p>:</span>
</span><span id=__span-4-2><a id=__codelineno-4-2 name=__codelineno-4-2 href=#__codelineno-4-2></a><span class=w>    </span><span class="p p-Indicator">-</span><span class=w> </span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class="l l-Scalar l-Scalar-Plain">plain</span>
</span><span id=__span-4-3><a id=__codelineno-4-3 name=__codelineno-4-3 href=#__codelineno-4-3></a><span class=w>        </span><span class="l l-Scalar l-Scalar-Plain">port</span><span class="p p-Indicator">:</span><span class=w> </span><span class="l l-Scalar l-Scalar-Plain">9092</span>
</span><span id=__span-4-4><a id=__codelineno-4-4 name=__codelineno-4-4 href=#__codelineno-4-4></a><span class=w>        </span><span class="l l-Scalar l-Scalar-Plain">type</span><span class="p p-Indicator">:</span><span class=w> </span><span class="l l-Scalar l-Scalar-Plain">internal</span>
</span><span id=__span-4-5><a id=__codelineno-4-5 name=__codelineno-4-5 href=#__codelineno-4-5></a><span class=w>        </span><span class="l l-Scalar l-Scalar-Plain">tls</span><span class="p p-Indicator">:</span><span class=w> </span><span class="l l-Scalar l-Scalar-Plain">false</span>
</span><span id=__span-4-6><a id=__codelineno-4-6 name=__codelineno-4-6 href=#__codelineno-4-6></a><span class=w>    </span><span class="p p-Indicator">-</span><span class=w> </span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class="l l-Scalar l-Scalar-Plain">tls</span>
</span><span id=__span-4-7><a id=__codelineno-4-7 name=__codelineno-4-7 href=#__codelineno-4-7></a><span class=w>        </span><span class="l l-Scalar l-Scalar-Plain">port</span><span class="p p-Indicator">:</span><span class=w> </span><span class="l l-Scalar l-Scalar-Plain">9093</span>
</span><span id=__span-4-8><a id=__codelineno-4-8 name=__codelineno-4-8 href=#__codelineno-4-8></a><span class=w>        </span><span class="l l-Scalar l-Scalar-Plain">type</span><span class="p p-Indicator">:</span><span class=w> </span><span class="l l-Scalar l-Scalar-Plain">internal</span>
</span><span id=__span-4-9><a id=__codelineno-4-9 name=__codelineno-4-9 href=#__codelineno-4-9></a><span class=w>        </span><span class="l l-Scalar l-Scalar-Plain">tls</span><span class="p p-Indicator">:</span><span class=w> </span><span class="l l-Scalar l-Scalar-Plain">true</span>
</span><span id=__span-4-10><a id=__codelineno-4-10 name=__codelineno-4-10 href=#__codelineno-4-10></a><span class=w>        </span><span class="l l-Scalar l-Scalar-Plain">authentication</span><span class="p p-Indicator">:</span>
</span><span id=__span-4-11><a id=__codelineno-4-11 name=__codelineno-4-11 href=#__codelineno-4-11></a><span class=w>        </span><span class=nt>type</span><span class=p>:</span><span class=w> </span><span class="l l-Scalar l-Scalar-Plain">tls</span>
</span><span id=__span-4-12><a id=__codelineno-4-12 name=__codelineno-4-12 href=#__codelineno-4-12></a><span class=w>    </span><span class="p p-Indicator">-</span><span class=w> </span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class="l l-Scalar l-Scalar-Plain">external</span>
</span><span id=__span-4-13><a id=__codelineno-4-13 name=__codelineno-4-13 href=#__codelineno-4-13></a><span class=w>        </span><span class="l l-Scalar l-Scalar-Plain">type</span><span class="p p-Indicator">:</span><span class=w> </span><span class="l l-Scalar l-Scalar-Plain">route</span>
</span><span id=__span-4-14><a id=__codelineno-4-14 name=__codelineno-4-14 href=#__codelineno-4-14></a><span class=w>        </span><span class="l l-Scalar l-Scalar-Plain">port</span><span class="p p-Indicator">:</span><span class=w> </span><span class="l l-Scalar l-Scalar-Plain">9094</span>
</span><span id=__span-4-15><a id=__codelineno-4-15 name=__codelineno-4-15 href=#__codelineno-4-15></a><span class=w>        </span><span class="l l-Scalar l-Scalar-Plain">tls</span><span class="p p-Indicator">:</span><span class=w> </span><span class="l l-Scalar l-Scalar-Plain">true</span><span class=w> </span>
</span><span id=__span-4-16><a id=__codelineno-4-16 name=__codelineno-4-16 href=#__codelineno-4-16></a><span class=w>        </span><span class="l l-Scalar l-Scalar-Plain">authentication</span><span class="p p-Indicator">:</span>
</span><span id=__span-4-17><a id=__codelineno-4-17 name=__codelineno-4-17 href=#__codelineno-4-17></a><span class=w>        </span><span class=nt>type</span><span class=p>:</span><span class=w> </span><span class="l l-Scalar l-Scalar-Plain">scram-sha-512</span>
</span></code></pre></div> </details> <details class="- question"> <summary>What are <code>ssl.truststore.location</code> and <code>ssl.truststore.password</code>?</summary> <p>When doing TLS encryption, we need to provide the Kafka clients with the location of a trusted Certificate Authority-based certificate. This file is often provided by the Kafka administrator and is generally unique to the specific Kafka cluster deployment. The certificate is in JKS format for JVM languages and PEM/ P12 for nodejs or Python.</p> <p>To extract a PEM-based certificate from a JKS-based truststore, we can use the following command: </p> <div class="language-text highlight"><pre><span></span><code><span id=__span-5-1><a id=__codelineno-5-1 name=__codelineno-5-1 href=#__codelineno-5-1></a>keytool -exportcert -keypass {truststore-password} -keystore {provided-kafka-truststore.jks} -rfc -file {desired-kafka-cert-output.pem}
</span></code></pre></div> </details> <details class="- question"> <summary>What are the security configuration to consider?</summary> <p>On Kubernetes, Kafka can be configured with external and internal URLs. With Strimzi internal URLs are using TLS or Plain authentication, then TLS for encryption. If no authentication property is specified then the listener does not authenticate clients which connect through that listener. The listener will accept all connections without authentication.</p> <ul> <li>Mutual TLS authentication for internal communication looks like:</li> </ul> <div class="language-yaml highlight"><pre><span></span><code><span id=__span-6-1><a id=__codelineno-6-1 name=__codelineno-6-1 href=#__codelineno-6-1></a><span class="p p-Indicator">-</span><span class=w> </span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class="l l-Scalar l-Scalar-Plain">tls</span>
</span><span id=__span-6-2><a id=__codelineno-6-2 name=__codelineno-6-2 href=#__codelineno-6-2></a><span class=w>    </span><span class="l l-Scalar l-Scalar-Plain">port</span><span class="p p-Indicator">:</span><span class=w> </span><span class="l l-Scalar l-Scalar-Plain">9093</span>
</span><span id=__span-6-3><a id=__codelineno-6-3 name=__codelineno-6-3 href=#__codelineno-6-3></a><span class=w>    </span><span class="l l-Scalar l-Scalar-Plain">type</span><span class="p p-Indicator">:</span><span class=w> </span><span class="l l-Scalar l-Scalar-Plain">internal</span>
</span><span id=__span-6-4><a id=__codelineno-6-4 name=__codelineno-6-4 href=#__codelineno-6-4></a><span class=w>    </span><span class="l l-Scalar l-Scalar-Plain">tls</span><span class="p p-Indicator">:</span><span class=w> </span><span class="l l-Scalar l-Scalar-Plain">true</span>
</span><span id=__span-6-5><a id=__codelineno-6-5 name=__codelineno-6-5 href=#__codelineno-6-5></a><span class=w>    </span><span class="l l-Scalar l-Scalar-Plain">authentication</span><span class="p p-Indicator">:</span>
</span><span id=__span-6-6><a id=__codelineno-6-6 name=__codelineno-6-6 href=#__codelineno-6-6></a><span class=w>    </span><span class=nt>type</span><span class=p>:</span><span class=w> </span><span class="l l-Scalar l-Scalar-Plain">tls</span>
</span></code></pre></div> <p>To connect any app (producer, consumer) we need a TLS user like:</p> <div class="language-yaml highlight"><pre><span></span><code><span id=__span-7-1><a id=__codelineno-7-1 name=__codelineno-7-1 href=#__codelineno-7-1></a><span class=nt>piVersion</span><span class=p>:</span><span class=w> </span><span class="l l-Scalar l-Scalar-Plain">kafka.strimzi.io/v1beta2</span>
</span><span id=__span-7-2><a id=__codelineno-7-2 name=__codelineno-7-2 href=#__codelineno-7-2></a><span class=nt>kind</span><span class=p>:</span><span class=w> </span><span class="l l-Scalar l-Scalar-Plain">KafkaUser</span>
</span><span id=__span-7-3><a id=__codelineno-7-3 name=__codelineno-7-3 href=#__codelineno-7-3></a><span class=nt>metadata</span><span class=p>:</span>
</span><span id=__span-7-4><a id=__codelineno-7-4 name=__codelineno-7-4 href=#__codelineno-7-4></a><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class="l l-Scalar l-Scalar-Plain">tls-user</span>
</span><span id=__span-7-5><a id=__codelineno-7-5 name=__codelineno-7-5 href=#__codelineno-7-5></a><span class=nt>labels</span><span class=p>:</span>
</span><span id=__span-7-6><a id=__codelineno-7-6 name=__codelineno-7-6 href=#__codelineno-7-6></a><span class=w>    </span><span class=nt>strimzi.io/cluster</span><span class=p>:</span><span class=w> </span><span class="l l-Scalar l-Scalar-Plain">vaccine-kafka</span>
</span><span id=__span-7-7><a id=__codelineno-7-7 name=__codelineno-7-7 href=#__codelineno-7-7></a><span class=nt>spec</span><span class=p>:</span>
</span><span id=__span-7-8><a id=__codelineno-7-8 name=__codelineno-7-8 href=#__codelineno-7-8></a><span class=nt>authentication</span><span class=p>:</span>
</span><span id=__span-7-9><a id=__codelineno-7-9 name=__codelineno-7-9 href=#__codelineno-7-9></a><span class=w>    </span><span class=nt>type</span><span class=p>:</span><span class=w> </span><span class="l l-Scalar l-Scalar-Plain">tls</span>
</span></code></pre></div> <p>Then the following configurations need to be done for each app. For example in Quarkus app, we need to specify where to find the client certificate (for each Kafka TLS user a secret is created with the certificate (ca.crt) and a user password)</p> <div class="language-shell highlight"><pre><span></span><code><span id=__span-8-1><a id=__codelineno-8-1 name=__codelineno-8-1 href=#__codelineno-8-1></a>oc<span class=w> </span>describe<span class=w> </span>secret<span class=w> </span>tls-user
</span><span id=__span-8-2><a id=__codelineno-8-2 name=__codelineno-8-2 href=#__codelineno-8-2></a><span class=nv>Data</span>
</span><span id=__span-8-3><a id=__codelineno-8-3 name=__codelineno-8-3 href=#__codelineno-8-3></a><span class=o>====</span>
</span><span id=__span-8-4><a id=__codelineno-8-4 name=__codelineno-8-4 href=#__codelineno-8-4></a>ca.crt:<span class=w>         </span><span class=m>1164</span><span class=w> </span>bytes
</span><span id=__span-8-5><a id=__codelineno-8-5 name=__codelineno-8-5 href=#__codelineno-8-5></a>user.crt:<span class=w>       </span><span class=m>1009</span><span class=w> </span>bytes
</span><span id=__span-8-6><a id=__codelineno-8-6 name=__codelineno-8-6 href=#__codelineno-8-6></a>user.key:<span class=w>       </span><span class=m>1704</span><span class=w> </span>bytes
</span><span id=__span-8-7><a id=__codelineno-8-7 name=__codelineno-8-7 href=#__codelineno-8-7></a>user.p12:<span class=w>       </span><span class=m>2374</span><span class=w> </span>bytes
</span><span id=__span-8-8><a id=__codelineno-8-8 name=__codelineno-8-8 href=#__codelineno-8-8></a>user.password:<span class=w>  </span><span class=m>12</span><span class=w> </span>bytes
</span></code></pre></div> <p>For Java client we need the following security settings, to specify from which secret to get the keystore password and certificate. The certificate will be mounted to <code>/deployments/certs/user</code>. </p> <div class="language-shell highlight"><pre><span></span><code><span id=__span-9-1><a id=__codelineno-9-1 name=__codelineno-9-1 href=#__codelineno-9-1></a>%prod.kafka.security.protocol<span class=o>=</span>SSL
</span><span id=__span-9-2><a id=__codelineno-9-2 name=__codelineno-9-2 href=#__codelineno-9-2></a>%prod.kafka.ssl.keystore.location<span class=o>=</span>/deployments/certs/user/user.p12
</span><span id=__span-9-3><a id=__codelineno-9-3 name=__codelineno-9-3 href=#__codelineno-9-3></a>%prod.kafka.ssl.keystore.type<span class=o>=</span>PKCS12
</span></code></pre></div> <p>For the server side certificate, it will be in a truststore, which is mounted to <code>/deployments/certs/server</code> and from a secret (this secret is created at the cluster level).</p> <p>Also because we also use TLS for encryption we need:</p> <div class="language-sh highlight"><pre><span></span><code><span id=__span-10-1><a id=__codelineno-10-1 name=__codelineno-10-1 href=#__codelineno-10-1></a>%prod.kafka.ssl.protocol<span class=o>=</span>TLSv1.2
</span></code></pre></div> <p>Mutual TLS authentication is always used for the communication between Kafka brokers and ZooKeeper pods. For mutual, or two-way, authentication, both the server and the client present certificates.</p> <ul> <li>The <a href=http://kafka.apache.org/documentation/#adminclientconfigs_sasl.mechanism>sasl.mechanism</a> property is for defining the authentication protocol used. Possible values are:</li> </ul> <div class="language-text highlight"><pre><span></span><code><span id=__span-11-1><a id=__codelineno-11-1 name=__codelineno-11-1 href=#__codelineno-11-1></a>PLAIN (cleartext passwords, although they will be encrypted across the wire per security.protocol settings above)
</span><span id=__span-11-2><a id=__codelineno-11-2 name=__codelineno-11-2 href=#__codelineno-11-2></a>SCRAM-SHA-512 (modern Salted Challenge Response Authentication Mechanism)
</span><span id=__span-11-3><a id=__codelineno-11-3 name=__codelineno-11-3 href=#__codelineno-11-3></a>GSSAPI (Kerberos-supported authentication and the default if not specified otherwise)
</span></code></pre></div> <ul> <li> <p>SCRAM: (Salted Challenge Response Authentication Mechanism) is an authentication protocol that can establish mutual authentication using passwords. Strimzi can configure Kafka to use SASL (Simple Authentication and Security Layer) SCRAM-SHA-512 to provide authentication on both unencrypted and encrypted client connections.</p> <ul> <li>The listener declaration:</li> </ul> <div class="language-yaml highlight"><pre><span></span><code><span id=__span-12-1><a id=__codelineno-12-1 name=__codelineno-12-1 href=#__codelineno-12-1></a><span class="p p-Indicator">-</span><span class=w> </span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class="l l-Scalar l-Scalar-Plain">external</span>
</span><span id=__span-12-2><a id=__codelineno-12-2 name=__codelineno-12-2 href=#__codelineno-12-2></a><span class=nt>port</span><span class=p>:</span><span class=w> </span><span class="l l-Scalar l-Scalar-Plain">9094</span>
</span><span id=__span-12-3><a id=__codelineno-12-3 name=__codelineno-12-3 href=#__codelineno-12-3></a><span class=nt>type</span><span class=p>:</span><span class=w> </span><span class="l l-Scalar l-Scalar-Plain">route</span>
</span><span id=__span-12-4><a id=__codelineno-12-4 name=__codelineno-12-4 href=#__codelineno-12-4></a><span class=nt>tls</span><span class=p>:</span><span class=w> </span><span class="l l-Scalar l-Scalar-Plain">true</span>
</span><span id=__span-12-5><a id=__codelineno-12-5 name=__codelineno-12-5 href=#__codelineno-12-5></a><span class=nt>authentication</span><span class=p>:</span>
</span><span id=__span-12-6><a id=__codelineno-12-6 name=__codelineno-12-6 href=#__codelineno-12-6></a><span class=nt>type</span><span class=p>:</span><span class=w> </span><span class="l l-Scalar l-Scalar-Plain">scram-sha-512</span>
</span></code></pre></div> <ul> <li>Need a scram-user:</li> </ul> <div class="language-yaml highlight"><pre><span></span><code><span id=__span-13-1><a id=__codelineno-13-1 name=__codelineno-13-1 href=#__codelineno-13-1></a><span class=nt>apiVersion</span><span class=p>:</span><span class=w> </span><span class="l l-Scalar l-Scalar-Plain">kafka.strimzi.io/v1beta2</span>
</span><span id=__span-13-2><a id=__codelineno-13-2 name=__codelineno-13-2 href=#__codelineno-13-2></a><span class=nt>kind</span><span class=p>:</span><span class=w> </span><span class="l l-Scalar l-Scalar-Plain">KafkaUser</span>
</span><span id=__span-13-3><a id=__codelineno-13-3 name=__codelineno-13-3 href=#__codelineno-13-3></a><span class=nt>metadata</span><span class=p>:</span>
</span><span id=__span-13-4><a id=__codelineno-13-4 name=__codelineno-13-4 href=#__codelineno-13-4></a><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class="l l-Scalar l-Scalar-Plain">scram-user</span>
</span><span id=__span-13-5><a id=__codelineno-13-5 name=__codelineno-13-5 href=#__codelineno-13-5></a><span class=nt>labels</span><span class=p>:</span>
</span><span id=__span-13-6><a id=__codelineno-13-6 name=__codelineno-13-6 href=#__codelineno-13-6></a><span class=w>    </span><span class=nt>strimzi.io/cluster</span><span class=p>:</span><span class=w> </span><span class="l l-Scalar l-Scalar-Plain">vaccine-kafka</span>
</span><span id=__span-13-7><a id=__codelineno-13-7 name=__codelineno-13-7 href=#__codelineno-13-7></a><span class=nt>spec</span><span class=p>:</span>
</span><span id=__span-13-8><a id=__codelineno-13-8 name=__codelineno-13-8 href=#__codelineno-13-8></a><span class=nt>authentication</span><span class=p>:</span>
</span><span id=__span-13-9><a id=__codelineno-13-9 name=__codelineno-13-9 href=#__codelineno-13-9></a><span class=w>    </span><span class=nt>type</span><span class=p>:</span><span class=w> </span><span class="l l-Scalar l-Scalar-Plain">scram-sha-512</span>
</span></code></pre></div> </li> </ul> <p>Then the app properties need to have:</p> <div class="language-shell highlight"><pre><span></span><code><span id=__span-14-1><a id=__codelineno-14-1 name=__codelineno-14-1 href=#__codelineno-14-1></a>security.protocol<span class=o>=</span>SASL_SSL
</span><span id=__span-14-2><a id=__codelineno-14-2 name=__codelineno-14-2 href=#__codelineno-14-2></a>%prod.quarkus.openshift.env.mapping.KAFKA_SSL_TRUSTSTORE_PASSWORD.from-secret<span class=o>=</span><span class=si>${</span><span class=nv>KAFKA_CA_CERT_NAME</span><span class=p>:</span><span class=nv>kafka</span><span class=p>-cluster-ca-cert</span><span class=si>}</span>
</span><span id=__span-14-3><a id=__codelineno-14-3 name=__codelineno-14-3 href=#__codelineno-14-3></a>%prod.quarkus.openshift.env.mapping.KAFKA_SSL_TRUSTSTORE_PASSWORD.with-key<span class=o>=</span>ca.password
</span><span id=__span-14-4><a id=__codelineno-14-4 name=__codelineno-14-4 href=#__codelineno-14-4></a>%prod.quarkus.openshift.env.mapping.KAFKA_SCRAM_PWD.from-secret<span class=o>=</span><span class=si>${</span><span class=nv>KAFKA_USER</span><span class=p>:</span><span class=nv>scram</span><span class=p>-user</span><span class=si>}</span>
</span><span id=__span-14-5><a id=__codelineno-14-5 name=__codelineno-14-5 href=#__codelineno-14-5></a>%prod.quarkus.openshift.env.mapping.KAFKA_SCRAM_PWD.with-key<span class=o>=</span>password
</span><span id=__span-14-6><a id=__codelineno-14-6 name=__codelineno-14-6 href=#__codelineno-14-6></a>%prod.quarkus.openshift.mounts.kafka-cert.path<span class=o>=</span>/deployments/certs/server
</span><span id=__span-14-7><a id=__codelineno-14-7 name=__codelineno-14-7 href=#__codelineno-14-7></a>%prod.quarkus.openshift.secret-volumes.kafka-cert.secret-name<span class=o>=</span><span class=si>${</span><span class=nv>KAFKA_CA_CERT_NAME</span><span class=p>:</span><span class=nv>kafka</span><span class=p>-cluster-ca-cert</span><span class=si>}</span>
</span></code></pre></div> </details> <details class="- question"> <summary>What are the setting for <code>sasl.jaas.config</code>?</summary> <div class="language-text highlight"><pre><span></span><code><span id=__span-15-1><a id=__codelineno-15-1 name=__codelineno-15-1 href=#__codelineno-15-1></a>sasl.jaas.config = org.apache.kafka.common.security.plain.PlainLoginModule required username=&quot;{USERNAME}&quot; password=&quot;{PASSWORD}&quot;;
</span><span id=__span-15-2><a id=__codelineno-15-2 name=__codelineno-15-2 href=#__codelineno-15-2></a>sasl.jaas.config = org.apache.kafka.common.security.scram.ScramLoginModule required username=&quot;{USERNAME}&quot; password=&quot;{PASSWORD}&quot;;
</span></code></pre></div> </details> <details class="- question"> <summary>How internal and external broker listener work?</summary> <p>See <a href=https://rmoff.net/2018/08/02/kafka-listeners-explained/ >this article</a> to understand the listener configuration. Here is a config to be used in docker container:</p> <div class="language-text highlight"><pre><span></span><code><span id=__span-16-1><a id=__codelineno-16-1 name=__codelineno-16-1 href=#__codelineno-16-1></a>KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka:29092,EXTERNAL://localhost:9092
</span><span id=__span-16-2><a id=__codelineno-16-2 name=__codelineno-16-2 href=#__codelineno-16-2></a>KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT
</span><span id=__span-16-3><a id=__codelineno-16-3 name=__codelineno-16-3 href=#__codelineno-16-3></a>KAFKA_LISTENERS: EXTERNAL://0.0.0.0:9092,INTERNAL://kafka:29092
</span><span id=__span-16-4><a id=__codelineno-16-4 name=__codelineno-16-4 href=#__codelineno-16-4></a>KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
</span><span id=__span-16-5><a id=__codelineno-16-5 name=__codelineno-16-5 href=#__codelineno-16-5></a>KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
</span></code></pre></div> <p>For <strong>external connection</strong> to Strimzi cluster use the following, where USERNAME is a scram-user</p> <div class="language-sh highlight"><pre><span></span><code><span id=__span-17-1><a id=__codelineno-17-1 name=__codelineno-17-1 href=#__codelineno-17-1></a>bootstrap.servers<span class=o>={</span>kafka-cluster-name<span class=o>}</span>-kafka-bootstrap-<span class=o>{</span>namespace<span class=o>}</span>.<span class=o>{</span>kubernetes-cluster-fully-qualified-domain-name<span class=o>}</span>:443
</span><span id=__span-17-2><a id=__codelineno-17-2 name=__codelineno-17-2 href=#__codelineno-17-2></a>security.protocol<span class=o>=</span>SASL_SSL
</span><span id=__span-17-3><a id=__codelineno-17-3 name=__codelineno-17-3 href=#__codelineno-17-3></a>sasl.mechanism<span class=o>=</span>SCRAM-SHA-512
</span><span id=__span-17-4><a id=__codelineno-17-4 name=__codelineno-17-4 href=#__codelineno-17-4></a>sasl.jaas.config<span class=o>=</span>org.apache.kafka.common.security.scram.ScramLoginModule<span class=w> </span>required<span class=w> </span><span class=nv>username</span><span class=o>=</span><span class=s2>&quot;{USERNAME}&quot;</span><span class=w> </span><span class=nv>password</span><span class=o>=</span><span class=s2>&quot;{PASSWORD}&quot;</span><span class=p>;</span>
</span><span id=__span-17-5><a id=__codelineno-17-5 name=__codelineno-17-5 href=#__codelineno-17-5></a>ssl.truststore.location<span class=o>={</span>/provided/to/you/by/the/kafka/administrator<span class=o>}</span>
</span><span id=__span-17-6><a id=__codelineno-17-6 name=__codelineno-17-6 href=#__codelineno-17-6></a>ssl.truststore.password<span class=o>={</span>__provided_to_you_by_the_kafka_administrator__<span class=o>}</span>
</span></code></pre></div> <p>To get the user password get the user secret (oc or kubectl CLIs):</p> <div class="language-shell highlight"><pre><span></span><code><span id=__span-18-1><a id=__codelineno-18-1 name=__codelineno-18-1 href=#__codelineno-18-1></a>oc<span class=w> </span>get<span class=w> </span>secret<span class=w> </span>scram-user<span class=w> </span>-o<span class=w> </span><span class=nv>jsonpath</span><span class=o>=</span><span class=s1>&#39;{.data.admin_password}&#39;</span><span class=w> </span><span class=p>|</span><span class=w> </span>base64<span class=w> </span>--decode<span class=w> </span><span class=o>&amp;&amp;</span><span class=w> </span><span class=nb>echo</span><span class=w> </span><span class=s2>&quot;&quot;</span>
</span></code></pre></div> <p>To get the Bootstrap URL use: </p> <div class="language-text highlight"><pre><span></span><code><span id=__span-19-1><a id=__codelineno-19-1 name=__codelineno-19-1 href=#__codelineno-19-1></a>expost K_CLUSTER_NAME=mycluster
</span><span id=__span-19-2><a id=__codelineno-19-2 name=__codelineno-19-2 href=#__codelineno-19-2></a>export BOOTSTRAP=&quot;$(oc get route ${K_CLUSTER_NAME}-kafka-bootstrap -o jsonpath=&#39;{.spec.host}&#39;):443&quot;
</span></code></pre></div> <p>The <code>sasl.jaas.config</code> can come from an environment variable inside of a secret, but in fact it is already predefined in the scram user in Strimzi:</p> <div class="language-sh highlight"><pre><span></span><code><span id=__span-20-1><a id=__codelineno-20-1 name=__codelineno-20-1 href=#__codelineno-20-1></a>oc<span class=w> </span>get<span class=w> </span>secret<span class=w> </span>my-user<span class=w> </span>-o<span class=w> </span>json<span class=w> </span><span class=p>|</span><span class=w> </span>jq<span class=w> </span>-r<span class=w> </span><span class=s1>&#39;.data[&quot;sasl.jaas.config&quot;]&#39;</span><span class=w> </span><span class=p>|</span><span class=w> </span>base64<span class=w> </span>-d<span class=w> </span>-
</span></code></pre></div> <ul> <li>For <strong>internal communication</strong>, with PLAIN the setting is:</li> </ul> <div class="language-sh highlight"><pre><span></span><code><span id=__span-21-1><a id=__codelineno-21-1 name=__codelineno-21-1 href=#__codelineno-21-1></a>bootstrap.servers<span class=o>={</span>kafka-cluster-name<span class=o>}</span>-kafka-bootstrap.<span class=o>{</span>namespace<span class=o>}</span>.svc.cluster.local:9093
</span><span id=__span-21-2><a id=__codelineno-21-2 name=__codelineno-21-2 href=#__codelineno-21-2></a>security.protocol<span class=w> </span><span class=o>=</span><span class=w> </span>SASL_PLAINTEXT<span class=w> </span><span class=o>(</span>these<span class=w> </span>clients<span class=w> </span><span class=k>do</span><span class=w> </span>not<span class=w> </span>require<span class=w> </span>SSL-based<span class=w> </span>encryption<span class=w> </span>as<span class=w> </span>they<span class=w> </span>are<span class=w> </span><span class=nb>local</span><span class=w> </span>to<span class=w> </span>the<span class=w> </span>cluster<span class=o>)</span>
</span><span id=__span-21-3><a id=__codelineno-21-3 name=__codelineno-21-3 href=#__codelineno-21-3></a>sasl.mechanism<span class=w> </span><span class=o>=</span><span class=w> </span>PLAIN
</span><span id=__span-21-4><a id=__codelineno-21-4 name=__codelineno-21-4 href=#__codelineno-21-4></a>sasl.jaas.config<span class=w> </span><span class=o>=</span><span class=w> </span>org.apache.kafka.common.security.plain.PlainLoginModule<span class=w> </span>required<span class=w> </span><span class=nv>username</span><span class=o>=</span><span class=s2>&quot;{USERNAME}&quot;</span><span class=w> </span><span class=nv>password</span><span class=o>=</span><span class=s2>&quot;{PASSWORD}&quot;</span><span class=p>;</span>
</span></code></pre></div> <ul> <li>For internal authentication with mutual TLS the settings:</li> </ul> <div class="language-text highlight"><pre><span></span><code><span id=__span-22-1><a id=__codelineno-22-1 name=__codelineno-22-1 href=#__codelineno-22-1></a>security.protocol=SSL 
</span></code></pre></div> </details> <details class="- question"> <summary>App running not in same namespace as Kafka</summary> <p>Remember that if the application does not run in the same namespace as the kafka cluster then copy the secrets to the namespace with something like:</p> <div class="language-sh highlight"><pre><span></span><code><span id=__span-23-1><a id=__codelineno-23-1 name=__codelineno-23-1 href=#__codelineno-23-1></a><span class=k>if</span><span class=w> </span><span class=o>[[</span><span class=w> </span>-z<span class=w> </span><span class=k>$(</span>oc<span class=w> </span>get<span class=w> </span>secret<span class=w> </span><span class=si>${</span><span class=nv>TLS_USER</span><span class=si>}</span><span class=w> </span><span class=m>2</span>&gt;<span class=w> </span>/dev/null<span class=k>)</span><span class=w> </span><span class=o>]]</span>
</span><span id=__span-23-2><a id=__codelineno-23-2 name=__codelineno-23-2 href=#__codelineno-23-2></a><span class=k>then</span>
</span><span id=__span-23-3><a id=__codelineno-23-3 name=__codelineno-23-3 href=#__codelineno-23-3></a><span class=c1># As the project is personal to the user, we can keep a generic name for the secret</span>
</span><span id=__span-23-4><a id=__codelineno-23-4 name=__codelineno-23-4 href=#__codelineno-23-4></a>oc<span class=w> </span>get<span class=w> </span>secret<span class=w> </span><span class=si>${</span><span class=nv>TLS_USER</span><span class=si>}</span><span class=w> </span>-n<span class=w> </span><span class=si>${</span><span class=nv>KAFKA_NS</span><span class=si>}</span><span class=w> </span>-o<span class=w> </span>json<span class=w> </span><span class=p>|</span><span class=w> </span>jq<span class=w> </span>-r<span class=w> </span><span class=s1>&#39;.metadata.name=&quot;tls-user&quot;&#39;</span><span class=w> </span><span class=p>|</span><span class=w> </span>jq<span class=w> </span>-r<span class=w> </span><span class=s1>&#39;.metadata.namespace=&quot;&#39;</span><span class=si>${</span><span class=nv>YOUR_PROJECT_NAME</span><span class=si>}</span><span class=s1>&#39;&quot;&#39;</span><span class=w> </span><span class=p>|</span><span class=w> </span>oc<span class=w> </span>apply<span class=w> </span>-f<span class=w> </span>-
</span><span id=__span-23-5><a id=__codelineno-23-5 name=__codelineno-23-5 href=#__codelineno-23-5></a><span class=k>fi</span>
</span><span id=__span-23-6><a id=__codelineno-23-6 name=__codelineno-23-6 href=#__codelineno-23-6></a>
</span><span id=__span-23-7><a id=__codelineno-23-7 name=__codelineno-23-7 href=#__codelineno-23-7></a><span class=k>if</span><span class=w> </span><span class=o>[[</span><span class=w> </span>-z<span class=w> </span><span class=k>$(</span>oc<span class=w> </span>get<span class=w> </span>secret<span class=w> </span><span class=si>${</span><span class=nv>SCRAM_USER</span><span class=si>}</span><span class=w> </span><span class=m>2</span>&gt;<span class=w> </span>/dev/null<span class=k>)</span><span class=w> </span><span class=o>]]</span>
</span><span id=__span-23-8><a id=__codelineno-23-8 name=__codelineno-23-8 href=#__codelineno-23-8></a><span class=k>then</span>
</span><span id=__span-23-9><a id=__codelineno-23-9 name=__codelineno-23-9 href=#__codelineno-23-9></a><span class=w>    </span><span class=c1># As the project is personal to the user, we can keep a generic name for the secret</span>
</span><span id=__span-23-10><a id=__codelineno-23-10 name=__codelineno-23-10 href=#__codelineno-23-10></a><span class=w>    </span>oc<span class=w> </span>get<span class=w> </span>secret<span class=w> </span><span class=si>${</span><span class=nv>SCRAM_USER</span><span class=si>}</span><span class=w> </span>-n<span class=w> </span><span class=si>${</span><span class=nv>KAFKA_NS</span><span class=si>}</span><span class=w> </span>-o<span class=w> </span>json<span class=w> </span><span class=p>|</span><span class=w>  </span>jq<span class=w> </span>-r<span class=w> </span><span class=s1>&#39;.metadata.name=&quot;scram-user&quot;&#39;</span><span class=w> </span><span class=p>|</span><span class=w> </span>jq<span class=w> </span>-r<span class=w> </span><span class=s1>&#39;.metadata.namespace=&quot;&#39;</span><span class=si>${</span><span class=nv>YOUR_PROJECT_NAME</span><span class=si>}</span><span class=s1>&#39;&quot;&#39;</span><span class=w> </span><span class=p>|</span><span class=w> </span>oc<span class=w> </span>apply<span class=w> </span>-f<span class=w> </span>-
</span><span id=__span-23-11><a id=__codelineno-23-11 name=__codelineno-23-11 href=#__codelineno-23-11></a><span class=k>fi</span>
</span></code></pre></div> </details> <details class="- question"> <summary>How to protect data at rest?</summary> <ul> <li>Use encrypted file system for each brokers</li> <li>Encrypt data at the producer level, using some API, and then decode at the consumer level. The data in the append log will be encrypted.</li> </ul> </details> <h2 id=more-advanced-concepts>More advanced concepts<a class=headerlink href=#more-advanced-concepts title="Permanent link">&para;</a></h2> <details class="- question"> <summary>What is range partition assignment strategy?</summary> <p>There are multiple partition assignment strategies for a consumer, part of a consumer group, to get its partition to fetch data from. Members of the consumer group subscribe to the topics they are interested in and forward their subscriptions to a Kafka broker serving as the group coordinator. The coordinator selects one member to perform the group assignment and propagates the subscriptions of all members to it. Then assign(Cluster, GroupSubscription) is called to perform the assignment and the results are forwarded back to each respective members.</p> <p>Range assignor works on a per-topic basis: it lays out the available partitions in numeric order and the consumers in lexicographic order, and assign partition to each consumer so partition with the same id will be in the same consumer: topic-1-part-0 and topic-2-part-0 will be processed by consumer-0</p> </details> <details class="- question"> <summary>What is sticky assignor?</summary> <p>The CooperativeStickyAssignor helps supporting incremental cooperative re-balancing to the clients' group protocol, which allows consumers to keep all of their assigned partitions during a re-balance, and at the end, revoke only those which must be migrated to another consumer for overall cluster balance.</p> <p>The goal is to reduce unnecessary downtime due to unnecessary partition migration, by leveraging the sticky assignor which link consumer to partition id. See <a href=https://cwiki.apache.org/confluence/display/KAFKA/KIP-429%3A+Kafka+Consumer+Incremental+Rebalance+Protocol>KIP 429 for details.</a> </p> </details> <details class="- question"> <summary>How to get an homogeneous distribution of message to partitions?</summary> <p>Design the message key and hash coding for even distributed. Or implement a customer 'partitioner' by implementing the <a href=https://kafka.apache.org/24/javadoc/?org/apache/kafka/clients/producer/Partitioner.html>Partitioner</a> interface. </p> </details> <details class="- question"> <summary>How to ensure efficient join between two topics?</summary> <p>Need to use co-partitioning, which means having the same key in both topic, the same number of partitions and the same producer partitioner, which most likely should be the default one that uses the following formula: <strong>partition = hash(key) % numPartitions</strong>.</p> </details> <details class="- question"> <summary>What is transaction in Kafka?</summary> <p>Producer can use transaction begin, commit and rollback APIs while publishing events to a multi-partition topic. This is done by setting a unique transactionId as part of its configuration (with idempotence and min inflight record set to 1). Either all messages are successfully written or none of them are. There are some producer exception to consider to abort the transaction: any KafkaException for sure, but also OutOfSequenceTx which may happen when the PID is greater than the last one seen by the producer.</p> <p>See explanations <a href=../producer/#how-to-support-exactly-once-delivery>here</a>.</p> <p>And the <a href=https://cwiki.apache.org/confluence/display/KAFKA/KIP-98+-+Exactly+Once+Delivery+and+Transactional+Messaging>KIP 98</a></p> </details> <details class="- question"> <summary>What is the high watermark?</summary> <p>The high watermark offset is the offset of the last message that was successfully copied to all of the log’s replicas. A consumer can only read up to the high watermark offset to prevent reading un-replicated messages.</p> </details> <details class="- question"> <summary>What should we do for full queue exception or timeout exception on the producer side?</summary> <p>The brokers are running behind, so we need to add more brokers and redistribute partitions.</p> </details> <details class="- question"> <summary>How to send large messages?</summary> <p>We can set some properties at the broker, topic, consumer and producer level:</p> <ul> <li>Broker: consider the <a href=https://kafka.apache.org/documentation/#brokerconfigs_message.max.bytes>message.max.bytes</a> and <a href=https://kafka.apache.org/documentation/#brokerconfigs_replica.fetch.max.bytes>replica.fetch.max.bytes</a></li> <li>Consumer: <a href=https://kafka.apache.org/documentation/#consumerconfigs_max.partition.fetch.bytes>max.partition.fetch.bytes</a>. Records are fetched in batches by the consumer, so this properties gives the max amount of data per partition the server will return. Default 1 Megabyte</li> </ul> <p>Always considering the claim-check pattern, by writing the big file in a cloud object storage and then keep the unique URI in the event payload.</p> </details> <details class="- question"> <summary>How to maximize throughput?</summary> <p>For producer if you want to maximize throughput over low latency, set <a href=https://kafka.apache.org/documentation/#producerconfigs_batch.size>batch.size</a> and <a href=https://kafka.apache.org/documentation/#producerconfigs_linger.ms>linger.ms</a> to higher value. Linger delay producer, it will wait for up to the given delay to allow other records to be sent so that the sends can be batched together.</p> </details> <details class="- question"> <summary>Why Kafka Stream applications may impact cluster performance?</summary> <ul> <li>They may use internal hidden topics to persist their states for Ktable and GlobalKTable.</li> <li>Process input and output topics</li> </ul> </details> <details class="- question"> <summary>How message schema version is propagated?</summary> <p>The record includes a byte with the version number from the schema registry.</p> </details> <details class="- question"> <summary>Consumers do not see message in topic, what happens?</summary> <p>The brokers may have an issue on this partition. If a broker, part of the ISR list fails, then new leader election may delay the broker commit operation initiated by a producer. </p> <p>The consumer has a communication issue, or fails, so the consumer group re-balance is underway.</p> </details> <details class="- question"> <summary>How, the compression schema used, is known by the consumer?</summary> <p>The record header includes such metadata. So it is possible to have different compression schema per record.</p> </details> <details class="- question"> <summary>What does out-of-synch partition mean and when it occurs?</summary> <p>With partition leader and replication to the followers, the number of in-synch replicas is at least the number of expected replicas. For example for a replicas = 3 the in-synch is set to 2, and it represents the minimum number of replicas that must acknowledge a write for the write operation to be considered successful. The record is considered “committed” when all ISRs for a partition wrote to their log. Only committed records are readable from consumer.</p> <p>Therefore <code>out-of-synch</code> will happen if the followers are not able to send their acknowledge to the replica leader as quickly as expected.</p> </details> <h2 id=kafka-connect>Kafka Connect<a class=headerlink href=#kafka-connect title="Permanent link">&para;</a></h2> <details class="- question"> <summary>How to remove personal identifying information?</summary> <p>From the source connector in Kafka Connect, it is possible to add processing class to process the records before publishing them to Kafka topic, so that any Kafka Streams apps will not see PII.</p> </details> <details class="- question"> <summary>How to handle variable workload with Kafka Connector source connector?</summary> <p>Increase and decrease the number of Kafka connect workers based upon current application load.</p> </details> <h2 id=derived-products-related-questions>Derived products related questions<a class=headerlink href=#derived-products-related-questions title="Permanent link">&para;</a></h2> <details class="- question"> <summary>What are the competitors to Kafka?</summary> <ul> <li><a href=https://nats.io/ >NATS</a></li> <li><a href=https://vectorized.io/ >Redpanda</a> a Modern streaming platform for mission critical workloads, and is compatible with Kafka API. It is a cluster of brokers without any zookeepers. It also leverage the SSD technology to improve I/O operations.</li> <li> <p><a href=https://jbcodeforce.github.io/architecture/aws/#kinesis>AWS Kinesis</a></p> <ul> <li>Cloud service, managed by AWS staff, paid as you go, proportional to the shard (like partition) used.</li> <li>24h to 7 days persistence</li> <li>Number of shards are adaptable with throughput.</li> <li>Uses the concept of Kinesis data streams, which uses shards: data records are composed of a sequence number, a partition key and a data blob.</li> <li>restrictions on message size (1 MB) and consumption rate of messages (5 reads /s, &lt; 2MB per shard, 1000 write /s)</li> <li>Server side encryption using master key managed by AWS KMS</li> </ul> </li> <li> <p>GCP Pub/sub</p> </li> <li>Solace</li> <li> <p>Active MQ:</p> <ul> <li>Java based messaging server to be the JMS reference implementation, so it supports transactional messaging. </li> <li>various messaging protocols including AMQP, STOMP, and MQTT</li> <li>It maintains the delivery state of every message resulting in lower throughput.</li> <li>Can apply JMS message selector to consumer specific message</li> <li>Point to point or pub/sub, but servers push messages to consumer/subscribers</li> <li>Performance of both queue and topic degrades as the number of consumers rises</li> </ul> </li> <li> <p>Rabbit MQ:</p> <ul> <li>Support queues, with messages removed once consumed</li> <li>Add the concept of Exchange to route message to queues</li> <li>Limited throughput, but can send large message</li> <li>Support JMS, AMQP protocols, and participation to transaction</li> <li>Smart broker / dumb consumer model that focuses on consistently delivering messages to consumers.</li> </ul> </li> </ul> </details> <details class="- question"> <summary>Differences between AMQ Streams and Confluent</summary> <p><a href=https://access.redhat.com/documentation/en-us/red_hat_amq/2021.q2/html/amq_streams_on_openshift_overview/index>AMQ Streams</a> and Confluent are based on the open source Kafka, but Confluent as the main contributor to Kafka, is adding proprietary features to make the product more market-able, so we will not do a pure features comparison but a generic features comparison:</p> <table> <thead> <tr> <th>Feature</th> <th>Confluent</th> <th>AMQ Streams</th> </tr> </thead> <tbody> <tr> <td>Kafka open source</td> <td>Aligned within a month to the Kafka release</td> <td>Within 2 months after Kafka release</td> </tr> <tr> <td>Kafka API</td> <td>Same</td> <td>Same</td> </tr> <tr> <td>k8s / OpenShift deployment</td> <td>Helm "operator"</td> <td>Real Kubernetes Operator based on open source Strimzi</td> </tr> <tr> <td>Kafka Connectors</td> <td>Connectors hub to reference any connectors on the market, with some certified for Confluent.</td> <td>Open source connectors supported. Apache Camel offers a set of connectors not directly supported by Red Hat but useful in a BYO connectors. Fuse and Debezium can be used.</td> </tr> <tr> <td>Schema registry</td> <td>Proprietary API and schema</td> <td>Solution may leverage open source <a href=https://apicur.io>Apicur.io</a> schema registry which is compatible with Confluent API.</td> </tr> <tr> <td>Cruise control for auto cluster balancing</td> <td>Adds on</td> <td>Available via Operator</td> </tr> <tr> <td>Mirroring between clusters</td> <td>Replicator tool</td> <td>Mirror Maker 2 deployable and managed by Strimzi operator</td> </tr> <tr> <td>Multi region cluster</td> <td>Supported</td> <td>Supported</td> </tr> <tr> <td>Role Based access control</td> <td>Supported</td> <td>Supported with explicit user manifest, integrated with Red Hat SSO and OPA.</td> </tr> <tr> <td>ksql</td> <td>Open sourced licensed by Confluent</td> <td>Customer can use open source version of kSQL but meed to verify licensing for cloud deployment. SQL processing on Kafka Records may also being done with Apache Flink</td> </tr> <tr> <td>Kafka Streams</td> <td>Supported from Kafka Open Source</td> <td>Supported from Kafka Open Source. Also moving CEP and Streams processing to an external tool makes a lot more sense. Apache Flink should be considered. Not directly supported by Red Hat</td> </tr> <tr> <td>Storage</td> <td>NFS and tiered storage</td> <td>Block storage with replication to s3 buckets for long persisence using Kafka connector. S3 Connector is not supported by Red Hat.</td> </tr> <tr> <td>As a managed service</td> <td>Proprietary solution</td> <td>Same with: IBM Event Streams and Red Hat AMQ streams as a service</td> </tr> <tr> <td>Integration with IBM mainframe</td> <td>Not strategic - Weak</td> <td>Strong with IBM connector and deployment on Z and P</td> </tr> <tr> <td>Admin User Interface</td> <td>Control center</td> <td>Operator in OpenShift and 3nd party open-source user interface like Kafdrop, Kowl, work with AMQ Streams but without direct support from Red Hat</td> </tr> </tbody> </table> <p>As Kafka adoption is a strategic investment, it is important to grow the competency and skill set to manage kafka clusters. Zookeeper was an important element to complexify the cluster management, as 2.8 it is removed, so it should be simpler to manage cluster.</p> <p>With customers can influence the product roadmap, but it will kill the open source approach if only Confluent committers prioritize the feature requets. It is important to keep competitions and multi committers.</p> </details> <details class="- question"> <summary>Differences between Akka and Kafka?</summary> <p><a href=https://akka.io/ >Akka</a> is an open source toolkit for Scala or Java to simplify multithreading programming and makes application more reactive by adopting an asynchronous mechanism for I/O operations: database or HTTP request. To support asynchronous communication between 'actors', it uses messaging, internal to the JVM. Kafka is part of the architecture, while Akka is an implementation choice for one of the component of the business application deployed inside the architecture.</p> <p><a href=https://vertx.io/ >vert.x</a> is another open source implementation of such internal messaging mechanism but supporting more languages like, Java, Groovy, Ruby, JavaScript, Ceylon, Scala, and Kotlin.</p> </details> <details class="- question"> <summary>Is is possible to stream video to kafka?</summary> <p>Yes it is possible, but developers need to do that with care and real justification, and verify if video processing can be done from files at rest. If the goal is to classify streamed images in real-time then it may be possible.</p> <p>The <a href=https://towardsdatascience.com/kafka-in-action-building-a-distributed-multi-video-processing-pipeline-with-python-and-confluent-9f133858f5a0>following article, from Neeraj Krishna</a> illustrates a python implementation to send video frame every 3 images, do image classification using <code>ResNet50</code> model trained on ImageNet, embedded in python consumer. The results are saved in mongodb with the metadata needed to query after processing.</p> </details> <h2 id=other-faqs>Other FAQs<a class=headerlink href=#other-faqs title="Permanent link">&para;</a></h2> <ul> <li><a href="https://cloud.ibm.com/docs/services/EventStreams?topic=eventstreams-faqs">IBM Event streams on Cloud FAQ</a> </li> <li><a href=https://cwiki.apache.org/confluence/display/KAFKA/FAQ#FAQ-HowareKafkabrokersdependonZookeeper?>FAQ from Confluent</a></li> </ul> </article> </div> <script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script> </div> <button type=button class="md-top md-icon" data-md-component=top hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg> Back to top </button> </main> <footer class=md-footer> <nav class="md-footer__inner md-grid" aria-label=Footer> <a href=../ class="md-footer__link md-footer__link--prev" aria-label="Previous: Kafka"> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg> </div> <div class=md-footer__title> <span class=md-footer__direction> Previous </span> <div class=md-ellipsis> Kafka </div> </div> </a> <a href=../producer/ class="md-footer__link md-footer__link--next" aria-label="Next: Kafka Producer"> <div class=md-footer__title> <span class=md-footer__direction> Next </span> <div class=md-ellipsis> Kafka Producer </div> </div> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11z"/></svg> </div> </a> </nav> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-copyright> <div class=md-copyright__highlight> Copyright &copy; 2018 - 2024 Jerome Boyer </div> Made with <a href=https://squidfunk.github.io/mkdocs-material/ target=_blank rel=noopener> Material for MkDocs </a> </div> <div class=md-social> <a href=https://github.com/jbcodeforce target=_blank rel=noopener title=github.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 496 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg> </a> <a href=https://linkedin.com/in/jeromeboyer target=_blank rel=noopener title=linkedin.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3M135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5m282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9z"/></svg> </a> <a href target=_blank rel=noopener title class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M498.1 5.6c10.1 7 15.4 19.1 13.5 31.2l-64 416c-1.5 9.7-7.4 18.2-16 23s-18.9 5.4-28 1.6L284 427.7l-68.5 74.1c-8.9 9.7-22.9 12.9-35.2 8.1S160 493.2 160 480v-83.6c0-4 1.5-7.8 4.2-10.8l167.6-182.8c5.8-6.3 5.6-16-.4-22s-15.7-6.4-22-.7L106 360.8l-88.3-44.2C7.1 311.3.3 300.7 0 288.9s5.9-22.8 16.1-28.7l448-256c10.7-6.1 23.9-5.5 34 1.4"/></svg> </a> </div> </div> </div> </footer> </div> <div class=md-dialog data-md-component=dialog> <div class="md-dialog__inner md-typeset"></div> </div> <div class=md-progress data-md-component=progress role=progressbar></div> <script id=__config type=application/json>{"base": "../../..", "features": ["content.code.annotate", "content.tooltips", "content.code.copy", "search.highlight", "navigation.instant", "navigation.instant.progress", "navigation.tabs", "navigation.tabs.sticky", "navigation.instant", "navigation.tracking", "navigation.sections", "navigation.expand", "navigation.top", "navigation.footer"], "search": "../../../assets/javascripts/workers/search.d50fe291.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script> <script src=../../../assets/javascripts/bundle.13a4f30d.min.js></script> <script src=../../../javascripts/mathjax.js></script> <script src=https://unpkg.com/mathjax@3/es5/tex-mml-chtml.js></script> </body> </html>